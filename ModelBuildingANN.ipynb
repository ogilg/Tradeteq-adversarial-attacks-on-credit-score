{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Using the DataProcessor class to preprocess the data\n",
    "\n",
    "Preprocessing can basically be done with 2 function calls: .remove_columns() and .preprocess_data().\n",
    "\n",
    "However the class also includes more fine-grained functionality (see code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample file\n",
    "data_dir = r\"/Users/xingyuehuang/Downloads/Tradeteq-adversarial-attacks-on-credit-score-main 2\"\n",
    "co_file = os.path.join(data_dir, \"client_start_folder\",\"Co_600K_Jul2019_6M.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataProcessor object which loads the data from the right file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.DataProcessor import DataProcessor\n",
    "data_proc = DataProcessor(co_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define columns to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_info_features = [\"CompanyId\", \"CompanyNumber\",\"CompanyName\",\"imd\"]\n",
    "only_one_value_features = [\"Filled\", \"LimitedPartnershipsNumGenPartners\", \"LimitedPartnershipsNumLimPartners\",\\\n",
    "                          \"Status20190701\",\"CompanyStatus\"]\n",
    "complicated_features = [\"RegAddressAddressLine1\", \"RegAddressAddressLine2\", \"RegAddressCareOf\", \"RegAddressCounty\", \\\n",
    "                        \"RegAddressPOBox\", \"RegAddressPostCode\", \"RegAddressPostTown\",\"oa11\", \"PreviousName_1CompanyName\"]\n",
    "to_remove_cols = zero_info_features+only_one_value_features+complicated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc.remove_columns(to_remove_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define columns to be converted to numerical/string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_num_cols = [\"AccountsAccountRefDay\", \"AccountsAccountRefMonth\", \"oac1\"]\n",
    "to_str_cols = [\"ru11ind\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the date-Data processing: [[\"NewDuration Name\", \"Post Name\", \"Prev Name\"],...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_convert=[[\"dAccountsTimeGap\",\"dAccountsNextDueDate\",\"dAccountsLastMadeUpDate\"],\\\n",
    "              [\"dConfStmtTimeGap\",\"dConfStmtNextDueDate\",\"dConfStmtLastMadeUpDate\"],\\\n",
    "              [\"dReturnsTimeGap\",\"dReturnsNextDueDate\",\"dReturnsLastMadeUpDate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_proc.preprocess_data(to_num_cols, to_str_cols, date_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 479022, 1: 978})\n",
      "Counter({0: 119782, 1: 218})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Evaluating models with the ModelEvaluator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ModelEvaluator class is abstract, so that it is general enough to work for different types of models. You might have to build your child class if the syntax differs (see SKEvaluator example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from ModelEvaluationTools.SKEvaluator import SKEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg = xgb.XGBClassifier(learning_rate=0.3, max_depth=10, subsample=0.5, objective='binary:logistic', verbosity=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instance of RFEvaluator, a child of the ModelEvaluator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_model = SKEvaluator(xg, 'xg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_auc = xg_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves model to fitted_models folder\n",
    "# xg_model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try the artificial neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,BatchNormalization\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.isnan((X_train)).any()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Neural Network model...\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "print('Building Neural Network model...')\n",
    "opt = optimizers.Adam(lr = 0.0001) # hyper parameter\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "# Try some weight initialization, with different weight\n",
    "model.add(Dense(10, input_dim=X_train.shape[1],\n",
    "                kernel_initializer='normal',\n",
    "                #kernel_regularizer=regularizers.l2(0.02),\n",
    "                activation=\"relu\"))\n",
    "model.add(Dense(4,activation = \"relu\"))\n",
    "#model.add(Dense(10,\n",
    "                #kernel_regularizer=regularizers.l2(0.02),\n",
    "#                activation=\"relu\"))\n",
    "#model.add(Dense(10,activation = \"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "     tf.keras.metrics.AUC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.0102 - auc: 0.8840 - val_loss: 0.0096 - val_auc: 0.8744\n",
      "Epoch 2/5\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.0103 - auc: 0.8866 - val_loss: 0.0096 - val_auc: 0.8729\n",
      "Epoch 3/5\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.0102 - auc: 0.8843 - val_loss: 0.0096 - val_auc: 0.8760\n",
      "Epoch 4/5\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.0103 - auc: 0.8857 - val_loss: 0.0096 - val_auc: 0.8726\n",
      "Epoch 5/5\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.0102 - auc: 0.8880 - val_loss: 0.0096 - val_auc: 0.8669\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_data = (X_test,y_test),batch_size=500,shuffle = True)# change test size hyperparameter\n",
    "# Change the batch_size to 2000?  callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras =model.predict_proba(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375111919681611\n"
     ]
    }
   ],
   "source": [
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 9.1636450e-38 2.2642820e-36 ... 3.7701672e-01 4.1204277e-01\n",
      " 4.5231435e-01]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_pred_keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 batchsize really good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
