{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: change preproseeing to new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data that has already been preprocessed\n",
    "data_dir = os.getcwd()\n",
    "with open(os.path.join(data_dir, \"processing\", r\"train_preproc.p\"), 'rb') as data_file:\n",
    "    train_data = pickle.load(data_file)\n",
    "X_train, y_train = train_data[0], train_data[1]\n",
    "\n",
    "with open(os.path.join(data_dir, \"processing\", r\"test_preproc.p\"), 'rb') as data_file:\n",
    "    test_data = pickle.load(data_file)\n",
    "X_test, y_test = test_data[0], test_data[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that there are no nans in train data\n",
    "for column in X_train.columns:\n",
    "    assert sum(X_train[column].isnull()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0],\n",
    "    'penalty': ['l1','l2', 'elasticnet'],\n",
    "    'n_jobs': [-1],\n",
    "    'loss' : ['perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber','log', 'squared_hinge' ]\n",
    "}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(SGDClassifier(random_state=42),\n",
    "                  param_grid, refit='AUC', return_train_score=True)\n",
    "gs.fit(X_train, y_train)\n",
    "results = gs.cv_results_\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (gs.best_params_, gs.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding the best parameters first RandomizedSearchCV (to narrow down the parameters space) \n",
    "# then GridSearch For finding the best parameters\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "iris = load_iris()\n",
    "sgd = SGDClassifier(tol=1e-3, max_iter=10000, random_state=0, n_jobs=-1)\n",
    "distributions = dict(alpha=uniform(loc=0, scale=1), penalty=['l2', 'l1','elasticnet'],loss = ['perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber','log', 'squared_hinge'] )\n",
    "\n",
    "clf = RandomizedSearchCV(sgd, distributions, refit='roc_auc')#find best params based on AUC\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = clf.cv_results_\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss='log', alpha=0.04374782771527885, max_iter=10000, penalty ='l1', n_jobs=-1) # parameters to be adjusted to make most optimal \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKEvaluator should work with SGD since RF class has implicit functions fit, predict, \n",
    "predict_proba which are used inside SKEvaluator--> need to set loss=”modified_huber” though to have internal predict_prba call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ModelEvaluationTools.SKEvaluator import SKEvaluator\n",
    "#sgd_model = SKEvaluator(classifier, \"sgd\")\n",
    "#sgd_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_auc = sgd_model.evaluate(X_test, y_test) #evaluate here seems to be using predict_proba(X_test) but i need to use decision_function(X_test) with some loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play around with auc explicitly\n",
    "from sklearn.metrics import roc_auc_score\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, classifier.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only use this if loss=”modified_huber”\n",
    "roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to find the best parameters for the classifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import parfit.parfit as pf\n",
    "grid = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'penalty': ['l1'],\n",
    "    'n_jobs': [-1],\n",
    "    'loss' : ['perceptron', 'squared_loss', 'huber', 'modified_huber','log', 'squared_hinge' ]\n",
    "}\n",
    "#'perceptron', 'squared_loss', 'huber', \n",
    "#'epsilon_insensitive', 'squared_epsilon_insensitive'\n",
    "# 'modified_huber','log', 'squared_hinge'\n",
    "paramGrid = ParameterGrid(grid)\n",
    "bestModel, bestScore, allModels, allScores = (\n",
    "pf.bestFit(SGDClassifier, paramGrid,\n",
    "           X_train, y_train, X_test, y_test, \n",
    "           metric = roc_auc_score, \n",
    "           scoreLabel = \"AUC\"))\n",
    "#print(bestModel, bestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best found so far With parfit: SGDClassifier(loss='huber', n_jobs=-1, penalty='l1') 0.5100757967187792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves model to fitted_models folder\n",
    "#sgd_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
